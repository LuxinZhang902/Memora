# Memora

**Mission:** Make personal memories and life admin instantly answerableâ€”with verifiable evidenceâ€”while staying private by default.

![Memora Interface](docs/images/memora-screenshot.png)
*Memora's hybrid search finding relevant documents through semantic understanding*

## Features

- ğŸ¤ **Voice-First Interface** - Speak naturally or type your questions
- ğŸ” **Hybrid Search** - Combines keyword (BM25) + semantic vector search for accurate results
- ğŸ“„ **File Content Search** - Searches inside uploaded documents (PDFs, DOCX, images with OCR)
- ğŸ¯ **Grounded Answers** - AI responses cite specific files and content
- ğŸ”’ **Private by Default** - All data stored securely with user isolation
- ğŸ“ **Evidence Gallery** - View source documents that support each answer

## Quick Start

### Prerequisites

- **Node.js** 18+ and **pnpm**
- **Elasticsearch** 8.x running locally or remote
- **Google Cloud Storage** bucket (private by default)
- API keys: OpenAI, ElevenLabs, Fireworks

### Setup

1. **Install dependencies:**
   ```bash
   pnpm install
   ```

2. **Configure environment:**
   Copy `infrastructure/example.env` to `.env.local` and fill in your keys:
   ```bash
   cp infrastructure/example.env .env.local
   ```

   | Variable | Description |
   |----------|-------------|
   | `OPENAI_API_KEY` | OpenAI API key for planner + answer composer |
   | `ELEVENLABS_API_KEY` | ElevenLabs API key for STT/TTS |
   | `FIREWORKS_API_KEY` | Fireworks API key for embeddings |
   | `ES_HOST` | Elasticsearch host (default: `http://localhost:9200`) |
   | `ES_USERNAME` / `ES_PASSWORD` | Elasticsearch credentials |
   | `GCP_PROJECT_ID` | Google Cloud project ID |
   | `GCS_BUCKET` | GCS bucket name (must be private) |
   | `GOOGLE_APPLICATION_CREDENTIALS` | Path to GCP service account JSON (or use ADC) |
   | `DEMO_USER_ID` | Demo user ID for dev auth (default: `u_demo`) |

3. **Start Elasticsearch** (if local):
   ```bash
   docker run -d -p 9200:9200 -e "discovery.type=single-node" -e "xpack.security.enabled=false" docker.elastic.co/elasticsearch/elasticsearch:8.15.0
   ```

4. **Create Elasticsearch index:**
   ```bash
   pnpm create-index
   ```

5. **Seed demo data:**
   ```bash
   pnpm seed
   ```
   This creates two moments:
   - **Paris trip** (2023-05-20): photo, itinerary PDF, note
   - **DMV renewal** (2024-10-01): selfie, receipt PDF, note

6. **Start the dev server:**
   ```bash
   pnpm dev
   ```
   Open [http://localhost:3000](http://localhost:3000)

## Demo Flow

1. **Press "Speak"** or type a question:
   - _"When was the last time I went to Paris?"_
   - _"When did I renew my driver's license?"_

2. **Watch the pipeline:**
   - ElevenLabs STT â†’ text
   - OpenAI planner â†’ QueryPlan JSON
   - Elasticsearch â†’ matching moment + artifacts
   - GCS signed URLs â†’ evidence items
   - OpenAI composer â†’ 2-sentence grounded answer

3. **View evidence:**
   - Photos, PDFs, notes displayed in gallery
   - Click to open signed URL in new tab

4. **Debug panel:**
   - Toggle to see QueryPlan, ES DSL, highlights, timings

## Architecture

### Query Flow

```
User speaks â†’ STT (ElevenLabs)
            â†“
         Text query
            â†“
    OpenAI planner â†’ QueryPlan JSON
            â†“
    Hybrid Search (Elasticsearch)
    â”œâ”€ Moments Index (BM25 + Vector)
    â””â”€ File Contents Index (BM25 + Vector)
            â†“
    Result Fusion (score-based ranking)
            â†“
    Top moment + artifacts[] + file content
            â†“
    GCS signed URLs (10 min TTL)
            â†“
    OpenAI composer â†’ 2-sentence answer (with file context)
            â†“
    Frontend: AnswerCard + EvidenceGallery
```

### Hybrid Search Implementation

Memora uses a sophisticated hybrid search that combines:

1. **Keyword Search (BM25)** - Traditional text matching with fuzzy search for typos
2. **Semantic Search (Vector)** - Understands meaning using embeddings (nomic-embed-text-v1.5)
3. **Cross-Index Search** - Searches both moments and file contents simultaneously
4. **Score Fusion** - Ranks results by combined relevance score

**Example Query Flow:**
```
Query: "When did I renew my driver license?"
  â†“
[ES] ========== HYBRID SEARCH STARTING ==========
[ES] Query text: When is the last time I renew my driver license?
[ES] Has query vector: true
[ES] DSL saved to: logs/hybrid-search-2025-10-10T21-53-28-176Z.json
  â†“
[ES] ========== HYBRID SEARCH RESULTS ==========
[ES] Found: 0 moments, 1 files
[ES] *** TOP FILE MATCH ***
[ES] File name: my_note_driver_lisence.docx
[ES] Score: 0.79
[ES] Text preview: May.6 Preparation for driver license...
  â†“
[ES] *** RETURNING FILE-BASED RESULT ***
[ES] File content included: true
  â†“
[ComposeAnswer] ========== COMPOSING ANSWER ==========
[ComposeAnswer] *** FILE CONTENT FOUND ***
[ComposeAnswer] File name: my_note_driver_lisence.docx
[ComposeAnswer] Text preview: May.6 Preparation for driver license
                              Old driver license
                              Proof of current living address
  â†“
Answer: "You prepared for your driver license renewal on May 6, 
         as documented in 'my_note_driver_lisence.docx'."
```

**Key Features:**
- Finds semantically related content even without exact keyword matches
- Searches extracted text from PDFs, DOCX, and images (OCR)
- Generates embeddings for semantic similarity
- Falls back gracefully if vector search unavailable
- Logs detailed search flow for debugging

See [HYBRID_SEARCH_IMPLEMENTATION.md](./HYBRID_SEARCH_IMPLEMENTATION.md) for technical details.

### Tech Stack

- **Frontend:** Next.js 14 (App Router) + React + TypeScript + Tailwind
- **Backend:** Next.js API routes (server-side orchestration)
- **AI/Audio:** ElevenLabs STT/TTS, DedalusLabs LLM (planner + composer), Fireworks embeddings (nomic-embed-text-v1.5)
- **Search:** Elasticsearch 8 with hybrid search (BM25 + vector similarity via cosineSimilarity)
- **Storage:** Google Cloud Storage (private, signed URLs with 10min TTL)
- **Content Extraction:** PDF.js (PDFs), Mammoth (DOCX), EXIF-parser (images), DedalusLabs Vision (OCR)
- **Security:** CSP headers, server-side ES queries, user_id filter, GCS private bucket

## Security Defaults

- **Private by default:** GCS bucket is private; all access via V4 signed URLs (10 min TTL)
- **User isolation:** Every ES query includes `filter: { term: { user_id } }`
- **Server-side only:** ES DSL built server-side; client never sends raw queries
- **CSP headers:** `default-src 'self'`, strict frame/referrer policies
- **No content logging:** Only metadata (moment_id, timestamp, type) logged; no text/URLs

See [SECURITY.md](./SECURITY.md) for details.

## Scripts

| Command | Description |
|---------|-------------|
| `pnpm dev` | Start Next.js dev server |
| `pnpm build` | Build for production |
| `pnpm start` | Start production server |
| `pnpm create-index` | Create Elasticsearch index from mapping |
| `pnpm seed` | Seed demo moments (Paris trip, DMV renewal) |

## Project Structure

```
memora/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ page.tsx              # Main UI: mic, input, answer, evidence
â”‚   â”œâ”€â”€ layout.tsx            # Root layout (loads globals.css)
â”‚   â”œâ”€â”€ globals.css           # Tailwind imports
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ MicButton.tsx     # Record audio â†’ STT
â”‚   â”‚   â”œâ”€â”€ AnswerCard.tsx    # 2-sentence answer + chips
â”‚   â”‚   â”œâ”€â”€ EvidenceGallery.tsx  # Horizontal strip of evidence items
â”‚   â”‚   â””â”€â”€ DebugPanel.tsx    # Toggle to show plan/DSL/timings
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ plan/route.ts     # POST /api/plan â†’ planQuery
â”‚       â”œâ”€â”€ exec/route.ts     # POST /api/exec â†’ executeQuery
â”‚       â”œâ”€â”€ evidence/route.ts # POST /api/evidence â†’ buildEvidence
â”‚       â”œâ”€â”€ compose/route.ts  # POST /api/compose â†’ composeAnswer
â”‚       â”œâ”€â”€ stt/route.ts      # POST /api/stt â†’ sttTranscribe
â”‚       â””â”€â”€ ingest/route.ts   # POST /api/ingest â†’ ingestMoment
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ types.ts              # QueryPlan, Artifact, MomentDoc, EvidenceItem, GroundedAnswer
â”‚   â”œâ”€â”€ openai.ts             # planQuery, composeAnswer
â”‚   â”œâ”€â”€ elevenlabs.ts         # transcribeWebm, textToSpeech
â”‚   â”œâ”€â”€ fireworks.ts          # embedText
â”‚   â”œâ”€â”€ es.ts                 # createIndexIfNotExists, upsertMoment, searchMoments
â”‚   â”œâ”€â”€ gcs.ts                # signRead, signWrite
â”‚   â””â”€â”€ auth.ts               # requireUser (dev auth)
â”œâ”€â”€ convex/
â”‚   â”œâ”€â”€ convex.config.ts      # Minimal Convex schema
â”‚   â””â”€â”€ actions/
â”‚       â”œâ”€â”€ planQuery.ts      # httpAction â†’ OpenAI planner
â”‚       â”œâ”€â”€ executeQuery.ts   # httpAction â†’ ES search
â”‚       â”œâ”€â”€ buildEvidence.ts  # httpAction â†’ GCS signed URLs
â”‚       â”œâ”€â”€ composeAnswer.ts  # httpAction â†’ OpenAI composer
â”‚       â”œâ”€â”€ ingestMoment.ts   # httpAction â†’ embed + upsert ES
â”‚       â””â”€â”€ sttTranscribe.ts  # httpAction â†’ ElevenLabs STT
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ create_index.ts       # Create ES index from mapping
â”‚   â””â”€â”€ seed_moments.ts       # Seed demo moments
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ es-mapping.json       # Elasticsearch mapping (nested artifacts, dense_vector)
â”‚   â”œâ”€â”€ gcs-lifecycle.json    # GCS lifecycle policy (optional)
â”‚   â””â”€â”€ example.env           # Environment variable template
â”œâ”€â”€ middleware.ts             # CSP + secure headers
â”œâ”€â”€ next.config.js            # Next.js config (transpile convex, external packages)
â”œâ”€â”€ package.json              # Dependencies + scripts
â”œâ”€â”€ tsconfig.json             # TypeScript config
â”œâ”€â”€ tailwind.config.ts        # Tailwind config
â”œâ”€â”€ postcss.config.js         # PostCSS config
â”œâ”€â”€ .gitignore                # Ignore .env.local, node_modules, .next
â”œâ”€â”€ README.md                 # This file
â””â”€â”€ SECURITY.md               # Security posture + best practices
```

## Roadmap

### âœ… Completed
- [x] **Hybrid retrieval:** BM25 + vector similarity search across moments and file contents
- [x] **File content extraction:** PDFs, DOCX, images with OCR
- [x] **Semantic search:** Vector embeddings for meaning-based matching
- [x] **File management:** Upload, view, edit, delete files with metadata

### ğŸš§ In Progress
- [ ] **User ID consistency:** Fix DEMO_USER_ID vs authenticated user mismatch
- [ ] **Reranking:** Add reranker model for better result ordering

### ğŸ“‹ Planned
- [ ] **ElevenLabs TTS:** "Play" button for final answer (store MP3 in GCS)
- [ ] **Real auth:** Replace `DEMO_USER_ID` with proper authentication
- [ ] **Multi-user:** Add user management, session tokens
- [ ] **Mobile app:** React Native + same backend
- [ ] **Incremental ingestion:** Watch folder, auto-ingest photos/files
- [ ] **Multi-modal search:** CLIP embeddings for image content search

## License

MIT (hackathon MVP)
